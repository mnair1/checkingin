{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category -> words\n",
    "df = pd.read_table('finalDataSetYork.csv',\n",
    "                   sep=',', encoding='utf-8', names = [\"word\", \"sentiment\"])\n",
    "df.head(100)\n",
    "df.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the whole embedding matrix\n",
    "\n",
    "embeddings_index = {}\n",
    "f=open('glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    \n",
    "    embed = np.array(values[1:])\n",
    "    embed = ','.join(embed)\n",
    "    embed = np.fromstring( embed, dtype=np.float, sep=',' )\n",
    "    #print(embed)\n",
    "    #dtype=np.float32\n",
    "    #numpy. ndarray. astype(dtype)\n",
    "    embeddings_index[word] = embed\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings for available words\n",
    "\n",
    "\n",
    "import numpy\n",
    "# Embeddings for available words\n",
    "data_embeddings ={}\n",
    "unknown_words =[]\n",
    "count= 0\n",
    "for word in df[\"word\"].tolist():\n",
    "    if(word.lower() in embeddings_index.keys()):\n",
    "        count = count +1\n",
    "        if(word.lower() not in data_embeddings.keys()):\n",
    "            data_embeddings[word.lower()] = embeddings_index[word.lower()]\n",
    "        else:\n",
    "          print(word.lower())\n",
    "    else:\n",
    "        unknown_words.append(word)\n",
    "#data_embed_values = list(data_embeddings.values())\n",
    "\n",
    "#print(data_embeddings)\n",
    "print('Key Categories %s word vectors.' % len(df[\"word\"]))\n",
    "print('Final Embedding %s word vectors.' % len(data_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data_embedding.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "    \n",
    "with open('embeddings_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(embeddings_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_embedding.pickle', 'rb') as handle:\n",
    "   data_embeddings = pickle.load(handle)\n",
    "\n",
    "with open('embeddings_index.pickle', 'rb') as handle:\n",
    "    embeddings_index = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from scipy.spatial import distance\n",
    "# Processing the query\n",
    "unknownWords = []\n",
    "def predictions(query):\n",
    "  return_val = \"unknown\"\n",
    "  try:\n",
    "      query_embed = embeddings_index[query]\n",
    "  except:\n",
    "      print(query, \" - unknown\")\n",
    "      return_val = \"unknown\"\n",
    "  else:\n",
    "      #print(query_embed)\n",
    "      scores = {}\n",
    "      score_counts = {}\n",
    "     \n",
    "      for word, embed in data_embeddings.items():\n",
    "        category_df = df[df[\"word\"]==word]\n",
    "        #print(category_df['sentiment'].values[0])\n",
    "        category =category_df['sentiment'].values[0]\n",
    "      \n",
    "        dist = distance.euclidean(query_embed, embed)\n",
    "        #dist /= 6\n",
    "        scores[category] = scores.get(category, 0) + dist\n",
    "        score_counts[category] = score_counts.get(category, 0) + 1\n",
    "\n",
    "      for category, dist in scores.items():\n",
    "        dist = dist / score_counts[category]\n",
    "        scores[category] = dist\n",
    "        #print(scores)\n",
    "        #print(max(scores.items(), key=operator.itemgetter(1))[0])\n",
    "      #return scores\n",
    "      if('unknown' in scores.keys()):\n",
    "          del scores['unknown']\n",
    "      return_val= min(scores.items(), key=operator.itemgetter(1))[0]\n",
    "      #print(\"scores\" , scores)\n",
    "  return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "#print(process('sad'))\n",
    "#print(predictions('puneet1'))\n",
    "print(predictions('ecstatic'))\n",
    "print(predictions('gloomy'))\n",
    "print(predictions('somber'))\n",
    "print(predictions('dull'))\n",
    "print(predictions('tedious'))\n",
    "print(predictions('sick'))\n",
    "print(predictions('cry'))\n",
    "print(predictions('victory'))\n",
    "print(predictions('kick'))\n",
    "print(predictions('angry'))\n",
    "print(predictions('high'))\n",
    "print(predictions('climb'))\n",
    "print(predictions('crime'))\n",
    "print(predictions('high'))\n",
    "print(predictions('grounded'))\n",
    "print(predictions('flabbergasted'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions('insulted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df['category_encoded'] = labelencoder.fit_transform(df['sentiment'])\n",
    "category_df = pd.DataFrame(df['sentiment'].unique(), columns=['sentiment'])\n",
    "category_df['emotion_category'] = labelencoder.fit_transform(category_df['sentiment'])\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df['word'].tolist()\n",
    "categories = df['category_encoded'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for word in words:\n",
    "    category = predictions(word)\n",
    "    if(category==\"unknown\") :\n",
    "        print(word)\n",
    "    catdf = category_df[category_df['sentiment']==category]\n",
    "    predictions.append(catdf['emotion_category'].values[0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_List = list(zip(words, categories, predictions))\n",
    "zip_List2 = list(zip(zip_List, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(zip_List, columns =['word', 'sentiment', 'prediction'])\n",
    "df_new\n",
    "df_new.to_excel(\"output_CheckIn_withEucledianDist_glove_840B_300d_finalDataSetYork1.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(categories, predictions)\n",
    "pd.DataFrame(\n",
    "    cm,\n",
    "    index=[['actual', 'actual','actual','actual','actual','actual','actual', 'actual', 'actual','actual','actual','actual'], ['Angry', 'Anxiety/Stress', 'Fearful', 'Happy', 'Mixed/Unsure', 'Neutral', 'Other', 'Peaceful', 'Physical', 'Sad', 'Sleep', 'unknown']],\n",
    "    columns=[['predicted', 'predicted','predicted','predicted','predicted','predicted','predicted', 'predicted', 'predicted','predicted','predicted','predicted'], ['Angry', 'Anxiety/Stress', 'Fearful', 'Happy', 'Mixed/Unsure', 'Neutral', 'Other', 'Peaceful', 'Physical', 'Sad', 'Sleep', 'unknown']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "def get_metrics(y_test, y_predicted):\n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')\n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = get_metrics(categories, predictions)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
